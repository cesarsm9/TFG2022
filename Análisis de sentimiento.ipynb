{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISIS DE SENTIMIENTOS APLICADO A LOS TEXTOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuaderno se va a explicar como se han realizado los diferentes análisis de sentimiento a los textos mediante los códigos de Python.\n",
    "Digo diferentes porque se han realizado tres análisis con tres librerías diferentes.\n",
    "\n",
    "Estas librerías son:<br>\n",
    "\n",
    "**__TextBlob__**: Es una librería para el procesamiento de texto o muy conocida, usa NLTK que es otra librería para el procesamiento del lenguaje natural, y además versátil, que cuenta con traductor propio, pero como es una librería que los módulos de análisis de sentimiento está  especializado en el inglés, se utilizará el texto en inglés. TextBlob general el análisis de sentimiento teniendo en cuenta algoritmos basados en tokenización y en lexicon, los lexicon son diccionarios con ponderación de palabras diferenciándose en positivas y negativas en este caso.\n",
    "Los resultados de este análisis se representan en los campos de textblob_polarity que contiene la polaridad de los textos enteros, es decir, como de positivos o de negativos son, un texto con polaridad 1 es positivo y con polaridad -1 es negativo.\n",
    "Y en el campo textblob_subjetivity  que representa la subjetividad del texto, cuanto más alto sea el valor, más cerca esta de ser una hecho o una verdad universal, y cuanto más bajo más tiende a ser una opinión. Estos campos se representan en valores.\n",
    "\n",
    "**__VADER__**: Esta librería también esta basada en los textos en inglés. Sus iniciales corresponden a  Valence Aware Dictionary and Sentiment Reasoner. También es un algoritmo basado en un lexicon pero con una mecánica y valores diferentes a la hroa de conformar las frases, teniendo en cuenta signos de puntuación y creando n-gramas de palabras. Los resultados se traducen en un porcentaje de como de negativo, positivo o nautral es, además opera y crea el dato compound que señala de -1 a 1 cuanto de positivo es el texto. En el caso de este proyecto se recoge el valor de compound.\n",
    "\n",
    "**__pysentimiento__**: Está librería la encuento de especial interés para este trabajo ya que es una librería para el procesamiento del lenguaje natural que se especializa en el idioma español y dispone de alternativas muy interesantes como son el análisis de sentimiento, que dice si es positivo, neutro  o negativo, el análisis de emociones que indica si hay tristeza, alegría, enfado u otras emociones que se puede traducir en neutralidad, e incluso un detector de discurso de odio que se ha pasado.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las primeras librerias usaran textos en ingles, mientras que la última es una librería especializada en textos en español.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSEUDOCÓDIGOS\n",
    "\n",
    "Los pseudocódigos son muy sencillos por lo que se usará un pesudocódigo para los tres aunque luego se codifiquen por separado.\n",
    "\n",
    "Se conecta a la base de datos<br>\n",
    "Se recupera la tabla<br>\n",
    "Se extraen los textos en fila<br>\n",
    "Para textblob: Calcular y recoger polaridad y subjetividad<br>\n",
    "Para vader: Calcular y recoger la media o valor compuesto<br>\n",
    "Para pysentimiento = Recoger sentimientos, emociones y discurso de odio<br>\n",
    "\n",
    "Añadir columnas a la tabla<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto, se empieza a codificar, una librería por una. El proceso de insercción de columnas no se muestra en este cuaderno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXTBLOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se importan las librerías y se hace la conexión a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import codecs\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "\n",
    "codecs.register(lambda name: codecs.lookup('utf8') if name == 'utf8mb4' else None)\n",
    "\n",
    "database = mysql.connector.connect(\n",
    "    host= \"localhost\",\n",
    "    user= \"root\",\n",
    "    passwd= \"\",\n",
    "    database= \"TFG\",\n",
    "    use_unicode = True, \n",
    "    charset=\"utf8mb4\",\n",
    "    collation = \"utf8mb4_general_ci\"\n",
    ")\n",
    "database.set_charset_collation(\"utf8mb4\",\"utf8mb4_general_ci\")\n",
    "\n",
    "cursor= database.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acto seguido se codifica la función que calculará el sentimiento con esta librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = \"tweets_\" # se escoge tabla \n",
    "columna_texto = \"texto_ingles\" # se escoge columna de textos\n",
    "\n",
    "def textblob (tabla,columna_texto):\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tabla}\",database) # se importan datos\n",
    "\n",
    "\n",
    "    sql = f\"UPDATE {tabla} SET textblob_polaridad = %s WHERE {columna_texto} = %s\"# se crea columna\n",
    "    sql2 = f\"UPDATE {tabla} SET textblob_subjetividad = %s WHERE {columna_texto} = %s\"# se crean columna\n",
    "\n",
    "    df = df[~df[columna_texto].isnull()]\n",
    "    print(df.info())\n",
    "    texto_en = df[columna_texto].tolist()\n",
    "\n",
    "    pol_list = []\n",
    "    subj_list = []\n",
    "    for a in tqdm(range(len(texto_en))): # se calcula la polaridad y la subjetividad\n",
    "        men = TextBlob(texto_en[a])\n",
    "        pol = float(men.sentiment.polarity)\n",
    "        pol_list.append(pol)\n",
    "        subj = float(men.sentiment.subjectivity)\n",
    "        subj_list.append(subj)\n",
    "\n",
    "    df[\"texblob_polaridad\"] = pol_list\n",
    "    df[\"textblob_subjetividad\"] = subj_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se importan las librerías y se hace la conexion a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import codecs\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "\n",
    "codecs.register(lambda name: codecs.lookup('utf8') if name == 'utf8mb4' else None)\n",
    "\n",
    "database = mysql.connector.connect(\n",
    "    host= \"localhost\",\n",
    "    user= \"root\",\n",
    "    passwd= \"\",\n",
    "    database= \"TFG\",\n",
    "    use_unicode = True, \n",
    "    charset=\"utf8mb4\",\n",
    "    collation = \"utf8mb4_general_ci\"\n",
    ")\n",
    "database.set_charset_collation(\"utf8mb4\",\"utf8mb4_general_ci\")\n",
    "\n",
    "cursor= database.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acto seguido se codifica la función que calcula los valores paraa los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = \"tweets\"\n",
    "columna_texto = \"texto_ingles\"\n",
    "\n",
    "\n",
    "def textblob (tabla,columna_texto):\n",
    "    import pandas as pd\n",
    "    analyzer = SentimentIntensityAnalyzer() # se crea el analizador de textos\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tabla}\",database)\n",
    "\n",
    "\n",
    "\n",
    "    df = df[~df[columna_texto].isnull()] # se eliminan textos nulos\n",
    "    print(df.info())\n",
    "    texto_en = df[columna_texto].tolist()\n",
    "\n",
    "    comp_list = []\n",
    "    for a  in tqdm(range(len(texto_en))):# se calcula el valor y se extare la media\n",
    "        vs = analyzer.polarity_scores(texto_en[a])\n",
    "        comp = vs[\"compound\"]\n",
    "        comp_list.append(comp)\n",
    "    df[\"vader\"] = comp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYSENTIMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se empieza importando a librerías y creando la conexión a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import codecs\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "from pysentimiento import create_analyzer\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "from tqdm import tqdm\n",
    "\n",
    "codecs.register(lambda name: codecs.lookup('utf8') if name == 'utf8mb4' else None)\n",
    "\n",
    "database = mysql.connector.connect(\n",
    "    host= \"localhost\",\n",
    "    user= \"root\",\n",
    "    passwd= \"\",\n",
    "    database= \"TFG\",\n",
    "    use_unicode = True, \n",
    "    charset=\"utf8mb4\",\n",
    "    collation = \"utf8mb4_general_ci\"\n",
    ")\n",
    "database.set_charset_collation(\"utf8mb4\",\"utf8mb4_general_ci\")\n",
    "\n",
    "cursor= database.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se continua ejecutando la función que identificara los sentimientos, la emocion y el odio de los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = \"tweets\"\n",
    "columna_texto = \"texto_espanol\"\n",
    "def textblob (tabla,columna_texto):\n",
    "    try: # se inserta las columnas si hace falta\n",
    "        sqlinsert = f\"ALTER TABLE {tabla} ADD pysen_sentimiento VARCHAR(4)\"\n",
    "        cursor.execute(sqlinsert)\n",
    "        sqlinsert2 = f\"ALTER TABLE {tabla} ADD pysen_emocion VARCHAR(10)\"\n",
    "        cursor.execute(sqlinsert2)\n",
    "        sqlinsert3 = f\"ALTER TABLE {tabla} ADD pysen_odio VARCHAR(50)\"\n",
    "        cursor.execute(sqlinsert3)\n",
    "    except:\n",
    "        pass\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tabla}\",database)# se lee la base de datps\n",
    "\n",
    "\n",
    "    sql = f\"UPDATE {tabla} SET pysen_sentimiento = %s WHERE {columna_texto} = %s\"\n",
    "    sql2 = f\"UPDATE {tabla} SET pysen_emocion = %s WHERE {columna_texto} = %s\"\n",
    "    sql3 = f\"UPDATE {tabla} SET pysen_odio = %s WHERE {columna_texto} = %s\"\n",
    "\n",
    "    df = df[~df[columna_texto].isnull()]\n",
    "    print(df.info())\n",
    "    texto_en = df[columna_texto].tolist()# se eliminan valores nulos si los hay\n",
    "\n",
    "    sentimiento = create_analyzer(task=\"sentiment\", lang=\"es\")# se crea el analizador de sentimientos\n",
    "    emocion = create_analyzer(task=\"emotion\", lang=\"es\")# se crea el analizador de emociones\n",
    "    odio = create_analyzer(task=\"hate_speech\", lang=\"es\") # se crea el detector de odio\n",
    "    odio_l = []\n",
    "    emo_l = []\n",
    "    sent_l = []\n",
    "    for a in tqdm(range(len(texto_en))): # se calcula y se recoge los resultados\n",
    "\n",
    "        pre = preprocess_tweet(texto_en[a])\n",
    "        sent = sentimiento.predict(pre).output\n",
    "        emo = emocion.predict(pre).output\n",
    "        odi =\" | \".join(odio.predict(pre).output)\n",
    "\n",
    "        odio_l.append(odi)\n",
    "        emo_l.append(emo)\n",
    "        sent_l.append(sent)\n",
    "        \n",
    "        \n",
    "    df[\"pysen_sentimiento\"] = sent_l\n",
    "    df[\"pysen_emocion\"] = emo_l\n",
    "    df[\"pysen_odio\"] = odio_l\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # CONCLUSIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de analaizar el texto con las tres librerías, la más rápida fue textblob, pero es la que se descarta debido a su alto porcentaje de error. <br<\n",
    "Vader analiza bien los textos con un porcentaje menor de error.<br>\n",
    "pysentimiento es la librería más compleja y por ello lo que más tarda, teniendo una diferencia de 4h con la de vader, qeu tarda 30min en analizar 1,2M de textos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b46891482e43448fca434b48535568d1fb045c476689b999f0b2c31bd471c5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
