{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCIÓN DE TOKENIZACIÓN HORIZONTAL DE TEXTOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un código sencillo que se aplca a ciertas tablas de la red social telegram en la que se necesita dividir el contenido de una columna en dos diferentes, aplica la teoria de la tokenización aunque no va a ser necesario ningun algoritmo especial ni sofisticado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSEUDOCÓDIGO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender mejor el procedimiento del código, se realizará un pseudocódigo más cercano al lenguaje humano.\n",
    "\n",
    "Concetar a la base de datos<br>\n",
    "Recoger columnas necesarias de la tabla<br>\n",
    "Selecionar los textos<br>\n",
    "hacer todos los caracteres minusculas<br>\n",
    "Separar texto en dos<br>\n",
    "para cada tupla<br>\n",
    "&emsp; identificar si su longitud es mayor a 2<br>\n",
    "&emsp; si es mayor que dos stopword <br>\n",
    "&emsp; &emsp; el primer elemento a una columna y el segundo a otra columna<br>\n",
    "&emsp; si no lo es<br>\n",
    "&emsp; &emsp; añadir 0  y null respectivamente a cada columna<br>\n",
    "\n",
    "&emsp; crear tabla con las nuevas columnas<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRERÍAS\n",
    "\n",
    "Este código no usa ninguna librería específica, el elemento clave en este código es la función .split() qeu nos permite dividir el texto por el carácter que tengamos.\n",
    "\n",
    "Otras librerías que se usan son:\n",
    "- **Pandas** : Manipulación de datos\n",
    "- **Mysql.connector**: Conexión con la base de datos\n",
    "- **Codecs**: Normalización de caracteres\n",
    "- **tqdm**: Enseña barra de progreso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez ya se explica todo, se da comienzo con el código de la tokenización, importando las librerias y creando la conexión a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import codecs\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "codecs.register(lambda name: codecs.lookup('utf8') if name == 'utf8mb4' else None)\n",
    "\n",
    "database = mysql.connector.connect(\n",
    "    host= \"localhost\",\n",
    "    user= \"root\",\n",
    "    passwd= \"\",\n",
    "    database= \"TFG\",\n",
    "    use_unicode = True, \n",
    "    charset=\"utf8mb4\",\n",
    "    collation = \"utf8mb4_general_ci\"\n",
    ")\n",
    "database.set_charset_collation(\"utf8mb4\",\"utf8mb4_general_ci\")\n",
    "\n",
    "cursor= database.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, se crea una función que será útil luego en el código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minusculas(x): #convierte el texto a minusculas\n",
    "    try:\n",
    "       x =  x.lower()\n",
    "    except:\n",
    "        pass\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acto seguido, se ejecuta el código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM tokenizado_linkedin_aptitud2\",database)\n",
    "\n",
    "\n",
    "\n",
    "tokens = df[\"tokens_espanol\"].to_list()\n",
    "\n",
    "numero = []\n",
    "texto = []\n",
    "for z in tqdm(range(len(tokens))):\n",
    "    print(tokens[z])\n",
    "    try:\n",
    "        listilla = tokens[z].split( \" | \")\n",
    "    except:\n",
    "        listilla = [0,\"null\"]\n",
    "    if len(listilla) <2:\n",
    "        numero.append(0)\n",
    "        texto.append(\"null\")\n",
    "    else:\n",
    "        numero.append(listilla[0])\n",
    "        texto.append(listilla[1])\n",
    "df[\"Numero\"] = numero\n",
    "df[\"Texto\"] = texto\n",
    "print(df.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez ya se tiene todo, se crea la nueva tabla y se inserta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataFrame   = pd.DataFrame(data=orden)           \n",
    "\n",
    "tableName = \"tokenizado_linkedin_aptitudes\"\n",
    "\n",
    "sqlEngine       = create_engine('mysql+pymysql://root:@127.0.0.1/TFG', pool_recycle=3600)\n",
    "\n",
    "dbConnection    = sqlEngine.connect()\n",
    "\n",
    " \n",
    "\n",
    "try:\n",
    "\n",
    "    frame           = dataFrame.to_sql(tableName, dbConnection, if_exists='fail');\n",
    "\n",
    "except ValueError as vx:\n",
    "\n",
    "    print(vx)\n",
    "\n",
    "except Exception as ex:   \n",
    "\n",
    "    print(ex)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Table %s created successfully.\"%tableName);   \n",
    "\n",
    "finally:\n",
    "\n",
    "    dbConnection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con este código se tokeniza todos los textos, cambiando la tabla y la columna\n",
    "\n",
    "# Tiene una duración de  menos de 30 segundos para 900K de registros. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b46891482e43448fca434b48535568d1fb045c476689b999f0b2c31bd471c5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
